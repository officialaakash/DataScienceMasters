{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0668b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider following code to answer further questions:\n",
    "# import pandas as pd\n",
    "# course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "# duration = [2,3,6,4]\n",
    "# df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18cc111",
   "metadata": {},
   "source": [
    "# Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df68d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "\n",
    "# Print the second row of the DataFrame\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151cc18",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723466d",
   "metadata": {},
   "source": [
    "The loc and iloc functions in pandas.DataFrame are used to access data from a DataFrame. The main difference between the two functions is how they handle indexing.\n",
    "\n",
    "The loc function is used to access data based on labels. It takes two arguments, row labels and column labels, and returns the selected data as a DataFrame. The row and column labels can be specified using their names or a boolean array. For example, df.loc[1, 'column_name'] will return the value in the second row and specified column name.\n",
    "\n",
    "The iloc function is used to access data based on integer positions. It takes two arguments, row position and column position, and returns the selected data as a DataFrame. The row and column positions start at 0 and are integers. For example, df.iloc[1, 2] will return the value in the second row and third column.\n",
    "\n",
    "In summary, the loc function uses label-based indexing, while the iloc function uses integer position-based indexing. Therefore, if you want to access data based on labels, use loc, and if you want to access data based on integer positions, use iloc.\n",
    "\n",
    "Example using loc function:h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567a890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "      A  B\n",
      "row1  1  4\n",
      "row2  2  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}, index=['row1', 'row2', 'row3'])\n",
    "\n",
    "# Access data using loc function\n",
    "print(df.loc['row1', 'A'])\n",
    "# Output: 1\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(df.loc[['row1', 'row2'], ['A', 'B']])  \n",
    "#Output \n",
    "#    A  B\n",
    "# row1  1  4\n",
    "# row2  2  5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f24bc",
   "metadata": {},
   "source": [
    "In this example, we create a sample DataFrame with three columns A, B, and C and three rows with index labels 'row1', 'row2', and 'row3'. We then use the loc function to access the data based on label-based indexing. The first example prints the value of the 'A' column in the 'row1' row. The second example prints the values of the 'A' and 'B' columns in the 'row1' and 'row2' rows.\n",
    "\n",
    "Example using iloc function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a107e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n",
      "   A  C\n",
      "0  1  7\n",
      "2  3  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "\n",
    "# Access data using iloc function\n",
    "print(df.iloc[0, 1])  \n",
    "# Output: 4\n",
    "\n",
    "print()\n",
    "\n",
    "print(df.iloc[[0, 2], [0, 2]])  \n",
    "# Output: \n",
    "#    A  C\n",
    "# 0  1  7\n",
    "# 2  3  9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e78c25",
   "metadata": {},
   "source": [
    "In this example, we create a sample DataFrame with three columns A, B, and C and three rows. We then use the iloc function to access the data based on integer position-based indexing. The first example prints the value of the second column in the first row. The second example prints the values of the first and third columns in the first and third rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39072868",
   "metadata": {},
   "source": [
    "# Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "# then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "\n",
    "# Did you observe any difference in both the outputs? If so then explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170faed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        course_name  duration\n",
      "0      Data Science         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "3     Data Engineer         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "\n",
    "#Printing original dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabbdeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        course_name  duration\n",
      "3     Data Engineer         4\n",
      "0      Data Science         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "--+----+----+----+----+----+----+----+--\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "--+----+----+----+----+----+----+----+--\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reindex = [3,0,1,2]\n",
    "\n",
    "#Reindexing\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "\n",
    "print(new_df)\n",
    "print(\"--+--\"*8)\n",
    "\n",
    "#prints output for both new_df.loc[2]\n",
    "print(new_df.loc[2])\n",
    "\n",
    "print(\"--+--\"*8)\n",
    "\n",
    "#prints output for both new_df.iloc[2]\n",
    "print(new_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9fbb4",
   "metadata": {},
   "source": [
    "As we can see, both new_df.loc[2] and new_df.iloc[2] return different outputs. The reason for this is that loc[] uses the index label to locate a row while iloc[] uses the integer location of the row. In our case, after reindexing, the index labels of new_df are [3, 0, 1, 2]. Therefore, new_df.loc[2] returns the row with index label 2 which is the row with the index label 1 of the original DataFrame df. On the other hand, new_df.iloc[2] returns the third row of new_df which is the row with the integer location 2 of the original DataFrame df. Hence, the two outputs are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce578c4a",
   "metadata": {},
   "source": [
    "# Consider the below code to answer further questions:\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "# indices = [1,2,3,4,5,6]\n",
    "# #Creating a dataframe:\n",
    "# df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b88237",
   "metadata": {},
   "source": [
    "# Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "# (i) mean of each and every column present in the dataframe.\n",
    "# (ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d82b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Means:\n",
      " column_1    0.579007\n",
      "column_2    0.258202\n",
      "column_3    0.707684\n",
      "column_4    0.528634\n",
      "column_5    0.517987\n",
      "column_6    0.509017\n",
      "dtype: float64\n",
      "\n",
      "----+--------+--------+--------+--------+----\n",
      "\n",
      "Standard Deviation of Column 2: 0.26366438724293045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each and every column present in the dataframe\n",
    "column_means = df1.mean()\n",
    "print('Column Means:\\n', column_means)\n",
    "\n",
    "print(\"\\n\"+ \"----+----\"*5 + \"\\n\")\n",
    "\n",
    "# (ii) Standard deviation of column, ‘column_2’\n",
    "column_std = df1['column_2'].std()\n",
    "print('Standard Deviation of Column 2:', column_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e993191",
   "metadata": {},
   "source": [
    "Here, we have used the mean() method to find the mean of each and every column present in the DataFrame df1. The resulting object is a pandas Series object containing the means of all columns.\n",
    "\n",
    "Similarly, we have used the std() method to find the standard deviation of the column named 'column_2'. The resulting output is a single value representing the standard deviation of the specified column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d2c74",
   "metadata": {},
   "source": [
    "# Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "# mean of column, column_2.\n",
    "# If you are getting errors in executing it then explain why.\n",
    "# [Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88c98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column_1  column_2  column_3  column_4  column_5  column_6\n",
      "1  0.977249  0.291051  0.349810  0.140889  0.028833  0.136311\n",
      "2  0.897949  0.038093  0.275504  0.726392  0.467061  0.005823\n",
      "3  0.612498  0.331558  0.100232  0.977794  0.879334  0.765199\n",
      "4  0.219596  0.878063  0.976760  0.596896  0.526158  0.622010\n",
      "5  0.920014  0.036734  0.948989  0.966100  0.412433  0.102836\n",
      "6  0.400234  0.046206  0.515434  0.995960  0.319367  0.419719\n",
      "   column_1            column_2  column_3  column_4  column_5  column_6\n",
      "1  0.977249            0.291051  0.349810  0.140889  0.028833  0.136311\n",
      "2  0.897949  replacement_string  0.275504  0.726392  0.467061  0.005823\n",
      "3  0.612498            0.331558  0.100232  0.977794  0.879334  0.765199\n",
      "4  0.219596            0.878063  0.976760  0.596896  0.526158  0.622010\n",
      "5  0.920014            0.036734  0.948989  0.966100  0.412433  0.102836\n",
      "6  0.400234            0.046206  0.515434  0.995960  0.319367  0.419719\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# find the mean of column_2\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_column_2)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11117\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11099\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11100\u001b[0m     _num_doc,\n\u001b[0;32m  11101\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11116\u001b[0m ):\n\u001b[1;32m> 11117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10687\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  10680\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10681\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10685\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  10686\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 10687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  10688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  10689\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10639\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10629\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  10630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  10631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10634\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  10635\u001b[0m     )\n\u001b[0;32m  10636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  10637\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  10638\u001b[0m     )\n\u001b[1;32m> 10639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  10641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4471\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4469\u001b[0m     )\n\u001b[0;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:410\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 410\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    413\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:698\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    695\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    697\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 698\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    701\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "print(df1)\n",
    "\n",
    "# replace the data in the second row of column_2 by a string variable\n",
    "df1.loc[2, 'column_2'] = 'replacement_string'\n",
    "print(df1)\n",
    "\n",
    "# find the mean of column_2\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "\n",
    "print(mean_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af187903",
   "metadata": {},
   "source": [
    "Yes, we will get a TypeError: unsupported operand type(s) for +: 'float' and 'str' . This error occurs because Python doesn't know how to add a string and a float together while calculating the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024631a9",
   "metadata": {},
   "source": [
    "# Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "# functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec8e9f",
   "metadata": {},
   "source": [
    "In pandas, a window function is a function that operates on a sliding window of data, which is defined by a window size and an optional window offset. Window functions are used to calculate aggregate statistics and other operations over a rolling or expanding window of data, rather than over the entire dataset.\n",
    "\n",
    "There are several types of window functions in pandas, including:\n",
    "\n",
    "1)Rolling window functions: These functions operate on a fixed-size window of data that slides over the data frame. Examples of rolling window functions include rolling, expanding, rolling_apply, and rolling_corr.\n",
    "\n",
    "2)Expanding window functions: These functions operate on a growing window of data that starts at the beginning of the data frame and expands until it encompasses the entire dataset. Examples of expanding window functions include expanding, expanding_apply, and expanding_sum.\n",
    "\n",
    "3)Exponential weighted window functions: These functions apply weights that decrease exponentially as the distance from the current point increases. Examples of exponential weighted window functions include ewm and ewmcorr.\n",
    "\n",
    "4)Aggregation functions: These functions are used to calculate summary statistics over a window of data, such as mean, median, sum, and standard deviation. Examples of aggregation functions include mean, sum, median, and std.\n",
    "\n",
    "5)Transformation functions: These functions are used to transform the data in a window, such as by applying a function to each element in the window or scaling the data to have a mean of zero and a standard deviation of one. Examples of transformation functions include apply and transform.\n",
    "\n",
    "Overall, window functions are a powerful tool for analyzing time series data and other sequential data in pandas, and they can be used to calculate a wide range of aggregate statistics and other operations over a rolling or expanding window of data.\n",
    "\n",
    "Rolling window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a39040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value\n",
      "0    NaN\n",
      "1    3.0\n",
      "2    5.0\n",
      "3    7.0\n",
      "4    9.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a data frame\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Calculate the rolling sum over a window of size 2\n",
    "rolling_sum = df.rolling(window=2).sum()\n",
    "\n",
    "print(rolling_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59109de",
   "metadata": {},
   "source": [
    "This code uses the rolling() function to calculate the rolling sum of a window of size 2 over the value column of the data frame.\n",
    "\n",
    "Expanding window function:m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b7a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value\n",
      "0    1.0\n",
      "1    3.0\n",
      "2    6.0\n",
      "3   10.0\n",
      "4   15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a data frame\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Calculate the expanding sum of the data\n",
    "expanding_sum = df.expanding().sum()\n",
    "\n",
    "print(expanding_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62575d13",
   "metadata": {},
   "source": [
    "This code uses the expanding() function to calculate the expanding sum of the value column of the data frame.\n",
    "\n",
    "Exponential weighted window function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1098de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value\n",
      "0  1.000000\n",
      "1  1.750000\n",
      "2  2.615385\n",
      "3  3.550000\n",
      "4  4.520661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a data frame\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Calculate the exponential moving average of the data with a span of 2\n",
    "ewma = df.ewm(span=2).mean()\n",
    "\n",
    "print(ewma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9ba1a",
   "metadata": {},
   "source": [
    "This code uses the ewm() function to calculate the exponential moving average of the value column of the data frame with a span of 2.\n",
    "\n",
    "Aggregation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1148f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value\n",
      "0    NaN\n",
      "1    1.5\n",
      "2    2.5\n",
      "3    3.5\n",
      "4    4.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a data frame\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Calculate the rolling mean over a window of size 2\n",
    "rolling_mean = df.rolling(window=2).mean()\n",
    "\n",
    "print(rolling_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e40868",
   "metadata": {},
   "source": [
    "This code uses the rolling() function to calculate the rolling mean of a window of size 2 over the value column of the data frame.\n",
    "\n",
    "Transformation function:\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6503804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1.264911\n",
      "1   -0.632456\n",
      "2    0.000000\n",
      "3    0.632456\n",
      "4    1.264911\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a data frame\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Scale the data to have a mean of zero and a standard deviation of one\n",
    "z_score = df['value'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74f0b0",
   "metadata": {},
   "source": [
    "\n",
    "This code uses the transform() function to scale the value column of the data frame to have a mean of zero and a standard deviation of one using a lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22619909",
   "metadata": {},
   "source": [
    "# Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "# [Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5425756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current month and year are: 4 2023\n"
     ]
    }
   ],
   "source": [
    "mport pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a pandas Timestamp object for the current date and time\n",
    "\n",
    "current_time = pd.Timestamp(datetime.now())\n",
    "\n",
    "# Get the current month and year from the Timestamp object\n",
    "current_month = current_time.month\n",
    "current_year = current_time.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"The current month and year are: {} {}\".format(current_month, current_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c321ca",
   "metadata": {},
   "source": [
    "# Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "# calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "# program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a9fd9",
   "metadata": {},
   "source": [
    "Here's a Python program that takes in two dates as input and calculates the difference between them in days, hours, and minutes using Pandas time delta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3aa49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first date in the format YYYY-MM-DD: 2023-02-22\n",
      "Enter the second date in the format YYYY-MM-DD: 2023-06-28\n",
      "The difference between 2023-02-22 00:00:00 and 2023-06-28 00:00:00 is 126 days, 0 hours, and 0 minutes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the dates\n",
    "date1 = input(\"Enter the first date in the format YYYY-MM-DD: \")\n",
    "date2 = input(\"Enter the second date in the format YYYY-MM-DD: \")\n",
    "\n",
    "# Convert the input strings to datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# Calculate the difference between the dates\n",
    "delta = date2 - date1\n",
    "\n",
    "# Extract the number of days, hours, and minutes from the timedelta object\n",
    "days = delta.days\n",
    "hours = delta.seconds // 3600\n",
    "minutes = (delta.seconds // 60) % 60\n",
    "\n",
    "# Display the result\n",
    "print(f\"The difference between {date1} and {date2} is {days} days, {hours} hours, and {minutes} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf1712",
   "metadata": {},
   "source": [
    "# Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "# column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "# name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95de4f",
   "metadata": {},
   "source": [
    "Here's a Python program that reads a CSV file containing categorical data, converts a specified column to a categorical data type, prompts the user to enter the file path, column name, and category order, and displays the sorted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f92b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path, column name, and category order\n",
    "file_path = input(\"Enter the file path: \")\n",
    "column_name = input(\"Enter the column name: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the specified column to a categorical data type\n",
    "data[column_name] = pd.Categorical(data[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the data by the specified column\n",
    "data_sorted = data.sort_values(by=column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(data_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d1505",
   "metadata": {},
   "source": [
    "# Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path for the CSV file: \")\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"\\n\\t\\tOriginal Data\\n\")\n",
    "print(df.head())\n",
    "print(\"----+----\"*7)\n",
    "\n",
    "# Convert the date column to a datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the DataFrame by date and product category, and sum the sales\n",
    "grouped_sales = df.groupby(['Date', 'Category'])['Sales'].sum().unstack()\n",
    "\n",
    "#Printing grouped sales data \n",
    "print(\"\\n\\tGrouped Sales data\\n\")\n",
    "print(grouped_sales.head())\n",
    "print(\"----+----\"*7)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "grouped_sales.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title('Sales by Product Category\\n')\n",
    "plt.xlabel('\\nDate')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dee55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd551b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
